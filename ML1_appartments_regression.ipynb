{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYRHI_Co7pti"
      },
      "source": [
        "# Machine Learning 1 - Regression on appartments dataset\n",
        "### Zofia Broszczak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SA8JBx2mnXz"
      },
      "source": [
        "# Packages and data import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "iAdJkZjJ1TRn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "import pickle\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from statsmodels.api import OLS, add_constant\n",
        "from statsmodels.tools.eval_measures import aic, bic\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_RRrYEW024n",
        "outputId": "d1a562eb-2496-4e2d-927a-0ad10c76a092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/.shortcut-targets-by-id/1eN-piwiant12j137Bx8TLRcvv0ejIF_w/ML1_2024_2025/_assessment_project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd '/content/drive/My Drive/ML1_2024_2025/_assessment_project'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "zuXipCHr1TWc"
      },
      "outputs": [],
      "source": [
        "appartments_train = pd.read_csv(\"data/appartments_train.csv\")\n",
        "appartments_test = pd.read_csv(\"data/appartments_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYqy7faLpYNy"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsf_mSnJhp5f"
      },
      "source": [
        "## Replacing missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "FyIttmSP2kYV"
      },
      "outputs": [],
      "source": [
        "appartments_train['obj_type'] = appartments_train['obj_type'].fillna('None')\n",
        "appartments_test['obj_type'] = appartments_test['obj_type'].fillna('None')\n",
        "\n",
        "appartments_train['build_mat'] = appartments_train['build_mat'].fillna('None') # material is missing in 40% of observations\n",
        "appartments_test['build_mat'] = appartments_test['build_mat'].fillna('None')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kpGAipbn-le9"
      },
      "outputs": [],
      "source": [
        "appartments_train = appartments_train.drop(columns=[\"cond_class\"]) # cond_class is missing in 75% of observations\n",
        "appartments_test = appartments_test.drop(columns=[\"cond_class\"])\n",
        "\n",
        "\n",
        "appartments_train = appartments_train.drop(columns=[\"unit_id\"]) # unit_id is unhelpful when modelling\n",
        "\n",
        "unit_ids = appartments_test['unit_id'].copy() #copying for predictions\n",
        "appartments_test = appartments_test.drop(columns=[\"unit_id\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3kDwcy72_Z6c"
      },
      "outputs": [],
      "source": [
        "appartments_train['floor_max'] = appartments_train['floor_max'].fillna(appartments_train['floor_max'].median())\n",
        "appartments_test['floor_max'] = appartments_test['floor_max'].fillna(appartments_test['floor_max'].median())\n",
        "\n",
        "appartments_train['dist_sch'] = appartments_train['dist_sch'].fillna(appartments_train['dist_sch'].median())\n",
        "appartments_test['dist_sch'] = appartments_test['dist_sch'].fillna(appartments_test['dist_sch'].median())\n",
        "\n",
        "appartments_train['dist_clinic'] = appartments_train['dist_clinic'].fillna(appartments_train['dist_clinic'].median())\n",
        "appartments_test['dist_clinic'] = appartments_test['dist_clinic'].fillna(appartments_test['dist_clinic'].median())\n",
        "\n",
        "appartments_train['dist_post'] = appartments_train['dist_post'].fillna(appartments_train['dist_post'].median())\n",
        "appartments_test['dist_post'] = appartments_test['dist_post'].fillna(appartments_test['dist_post'].median())\n",
        "\n",
        "appartments_train['dist_kind'] = appartments_train['dist_kind'].fillna(appartments_train['dist_kind'].median())\n",
        "appartments_test['dist_kind'] = appartments_test['dist_kind'].fillna(appartments_test['dist_kind'].median())\n",
        "\n",
        "appartments_train['dist_rest'] = appartments_train['dist_rest'].fillna(appartments_train['dist_rest'].median())\n",
        "appartments_test['dist_rest'] = appartments_test['dist_rest'].fillna(appartments_test['dist_rest'].median())\n",
        "\n",
        "appartments_train['dist_pharma'] = appartments_train['dist_pharma'].fillna(appartments_train['dist_pharma'].median())\n",
        "appartments_test['dist_pharma'] = appartments_test['dist_pharma'].fillna(appartments_test['dist_pharma'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "UboEI4HThcZX"
      },
      "outputs": [],
      "source": [
        "lift_mode = appartments_train['has_lift'].mode().iloc[0]\n",
        "\n",
        "appartments_train['has_lift'] = appartments_train['has_lift'].fillna(lift_mode)\n",
        "appartments_test['has_lift'] = appartments_test['has_lift'].fillna(lift_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "HFOyJNzdaoE-"
      },
      "outputs": [],
      "source": [
        "bins = [0, 5, 10, 15, 20, 30, 100]\n",
        "labels = ['0-5', '6-10', '11-15', '16-20', '21-30', '31+']\n",
        "\n",
        "appartments_train['floor_max_bin'] = pd.cut(appartments_train['floor_max'], bins=bins, labels=labels)\n",
        "\n",
        "floor_no_by_bin = appartments_train.groupby('floor_max_bin', observed=True)['floor_no'].median()\n",
        "\n",
        "appartments_train['floor_no'] = appartments_train.apply(lambda row: floor_no_by_bin[row['floor_max_bin']] if pd.isna(row['floor_no']) else row['floor_no'], axis=1)\n",
        "appartments_train.drop(columns=['floor_max_bin'], inplace=True)\n",
        "\n",
        "appartments_test['floor_max_bin'] = pd.cut(appartments_test['floor_max'], bins=bins, labels=labels)\n",
        "appartments_test['floor_no'] = appartments_test.apply(lambda row: floor_no_by_bin[row['floor_max_bin']] if pd.isna(row['floor_no']) else row['floor_no'], axis=1)\n",
        "appartments_test.drop(columns=['floor_max_bin'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "TiyDnDk-ewTQ"
      },
      "outputs": [],
      "source": [
        "year_built_by_loc = appartments_train.groupby('loc_code')['year_built'].median()\n",
        "year_median = appartments_train['year_built'].median()\n",
        "\n",
        "appartments_train['year_built'] = appartments_train['year_built'].fillna(appartments_train['loc_code'].map(year_built_by_loc)).fillna(year_median)\n",
        "appartments_test['year_built'] = appartments_test['year_built'].fillna(appartments_test['loc_code'].map(year_built_by_loc)).fillna(year_median)\n",
        "\n",
        "dist_uni_by_loc = appartments_train.groupby('loc_code')['dist_uni'].median()\n",
        "global_dist_uni_median = appartments_train['dist_uni'].median()\n",
        "\n",
        "appartments_train['dist_uni'] = appartments_train['dist_uni'].fillna(appartments_train['loc_code'].map(dist_uni_by_loc)).fillna(global_dist_uni_median)\n",
        "appartments_test['dist_uni'] = appartments_test['dist_uni'].fillna(appartments_test['loc_code'].map(dist_uni_by_loc)).fillna(global_dist_uni_median)\n",
        "\n",
        "infra_by_year = appartments_train.groupby('year_built')['infrastructure_quality'].median()\n",
        "global_infra_median = appartments_train['infrastructure_quality'].median()\n",
        "\n",
        "appartments_train['infrastructure_quality'] = appartments_train['infrastructure_quality'].fillna(appartments_train['year_built'].map(infra_by_year)).fillna(global_infra_median)\n",
        "appartments_test['infrastructure_quality'] = appartments_test['infrastructure_quality'].fillna(appartments_test['year_built'].map(infra_by_year)).fillna(global_infra_median)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hql8HYcQhu8Y"
      },
      "source": [
        "## Distribution of nominal variables (changing rare categories to \"other\")\n",
        " we will replace all the levels which have no more than 1565 observations (ca. 1% of the total sample) with the label \"other\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "0WF9-f_P2kVU"
      },
      "outputs": [],
      "source": [
        "nominal_variables = [\n",
        "    \"obj_type\",\n",
        "    \"own_type\",\n",
        "    \"build_mat\",\n",
        "    \"has_park\",\n",
        "    \"has_balcony\",\n",
        "    \"has_lift\",\n",
        "    \"has_sec\",\n",
        "    \"has_store\",\n",
        "    \"loc_code\"\n",
        "]\n",
        "\n",
        "rare_threshold = 1565 # < 1% od all observations\n",
        "\n",
        "value_counts = appartments_train['loc_code'].value_counts()\n",
        "rare_levels = value_counts[value_counts <= rare_threshold].index\n",
        "\n",
        "appartments_train['loc_code'] = appartments_train['loc_code'].replace(rare_levels, 'Other')\n",
        "appartments_test['loc_code'] = appartments_test['loc_code'].replace(rare_levels, 'Other')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "--fGI_5oRi9B"
      },
      "outputs": [],
      "source": [
        "appartments_train['price_z_log'] = np.log1p(appartments_train['price_z'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tikYBRY4TK1p"
      },
      "source": [
        "## Log transforming some numeric variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ddYAklqolUkA"
      },
      "outputs": [],
      "source": [
        "numeric_variables = appartments_train.select_dtypes(include=[np.number]).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "R4XKTxvBU7Ct"
      },
      "outputs": [],
      "source": [
        "log_features = [\"market_volatility\", \"n_rooms\", \"dim_m2\", \"estimated_maintenance_cost\", \"n_poi\",\"dist_centre\", \"dist_rest\", \"dist_clinic\", 'infrastructure_quality']\n",
        "\n",
        "for col in log_features:\n",
        "    appartments_train[col] = np.log1p(appartments_train[col])\n",
        "    appartments_test[col] = np.log1p(appartments_test[col])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRAi-WRgUgc9"
      },
      "source": [
        "# Binning selected numeric variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "4UHJvifdxriD"
      },
      "outputs": [],
      "source": [
        "appartments_train['floor_no_binned'] = pd.cut(appartments_train['floor_no'], bins=[0, 3, 7, 15, 100],labels=[\"Low\", \"Mid\", \"High\", \"Very High\"])\n",
        "appartments_test['floor_no_binned'] = pd.cut(appartments_test['floor_no'], bins=[0, 3, 7, 15, 100],labels=[\"Low\", \"Mid\", \"High\", \"Very High\"])\n",
        "\n",
        "appartments_train = appartments_train.drop(columns=[\"floor_no\"])\n",
        "appartments_test = appartments_test.drop(columns=[\"floor_no\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "CdN8RIvHxrfy"
      },
      "outputs": [],
      "source": [
        "appartments_train['floor_max_binned'] = pd.cut(appartments_train['floor_max'], bins=[0, 4, 10, 100],labels=[\"Low-rise\", \"Mid-rise\", \"High-rise\"])\n",
        "appartments_test['floor_max_binned'] = pd.cut(appartments_test['floor_max'], bins=[0, 4, 10, 100],labels=[\"Low-rise\", \"Mid-rise\", \"High-rise\"])\n",
        "\n",
        "\n",
        "appartments_train = appartments_train.drop(columns=[\"floor_max\"])\n",
        "appartments_test = appartments_test.drop(columns=[\"floor_max\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "WnOeHoIvxrdn"
      },
      "outputs": [],
      "source": [
        "appartments_train['year_binned'] = pd.cut(appartments_train['year_built'], bins=[1800, 1950, 1980, 2000, 2015, 2024],labels=[\"<1950\", \"1950–1980\", \"1980–2000\", \"2000–2015\", \"2015–2024\"])\n",
        "appartments_test['year_binned'] = pd.cut(appartments_test['year_built'], bins=[1800, 1950, 1980, 2000, 2015, 2024],labels=[\"<1950\", \"1950–1980\", \"1980–2000\", \"2000–2015\", \"2015–2024\"])\n",
        "\n",
        "\n",
        "appartments_train = appartments_train.drop(columns=[\"year_built\"])\n",
        "appartments_test = appartments_test.drop(columns=[\"year_built\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWEiwImuFq9W"
      },
      "source": [
        "# Standardizing continuous numerical features​\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "VgScGIzTFqJg"
      },
      "outputs": [],
      "source": [
        "# Scaling only float features\n",
        "float_cols = appartments_train.select_dtypes(include='float64').columns\n",
        "float_cols = [col for col in float_cols if col != 'price_z' and col != 'price_z_log']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "appartments_train.loc[:, float_cols] = scaler.fit_transform(appartments_train[float_cols])\n",
        "appartments_test.loc[:, float_cols] = scaler.transform(appartments_test[float_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXPwoXoKvJ0u"
      },
      "source": [
        "# Encoding ordinal variables\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "CjjgjWLfObsX"
      },
      "outputs": [],
      "source": [
        "appartments_train_encoded = appartments_train.copy()\n",
        "appartments_test_encoded = appartments_test.copy()\n",
        "\n",
        "\n",
        "ordinal_categories = [[\"Low\", \"Mid\", \"High\", \"Very High\"], [\"Low-rise\", \"Mid-rise\", \"High-rise\"], [\"<1950\", \"1950–1980\", \"1980–2000\", \"2000–2015\", \"2015–2024\"]]\n",
        "\n",
        "ordinal_variables_to_transform = [\"floor_no_binned\", \"floor_max_binned\", \"year_binned\"]\n",
        "\n",
        "encoder_ord = OrdinalEncoder(categories=ordinal_categories)\n",
        "\n",
        "appartments_train_encoded[ordinal_variables_to_transform] = encoder_ord.fit_transform(appartments_train[ordinal_variables_to_transform])\n",
        "\n",
        "appartments_test_encoded[ordinal_variables_to_transform] = encoder_ord.transform(appartments_test[ordinal_variables_to_transform])\n",
        "\n",
        "month_mapping = {'2023-08': 1, '2023-09': 2, '2023-10': 3, '2023-11': 4, '2023-12': 5, '2024-01': 6, '2024-02': 7, '2024-03': 8, '2024-04': 9, '2024-05': 10, '2024-06': 11}\n",
        "\n",
        "appartments_train_encoded['src_month'] = appartments_train['src_month'].map(month_mapping)\n",
        "appartments_test_encoded['src_month'] = appartments_test['src_month'].map(month_mapping)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GVsgZuJzsyv"
      },
      "source": [
        "#Encoding nominal variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "HM6zrXGlxrbB"
      },
      "outputs": [],
      "source": [
        "nominal_variables_left = [var for var in nominal_variables]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "3GXRctOqxrWE"
      },
      "outputs": [],
      "source": [
        "appartments_train_encoded = pd.get_dummies(appartments_train_encoded, columns = nominal_variables_left, drop_first = True, dtype = int)\n",
        "appartments_test_encoded = pd.get_dummies(appartments_test_encoded, columns = nominal_variables_left, drop_first = True, dtype = int)\n",
        "\n",
        "appartments_test_encoded = appartments_test_encoded.reindex(columns=appartments_train_encoded.columns,fill_value=0) # to ensure that the one-hot encoded test dataset has the exact same columns as the training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FluRaKtGpnQy"
      },
      "source": [
        "# Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daR1zmtDH9P1"
      },
      "source": [
        "## Quantitative explanatory variables - correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "uHFbuz_5H9P7"
      },
      "outputs": [],
      "source": [
        "appartments_numeric_columns = appartments_train.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "appartments_correlations = appartments_train[appartments_numeric_columns].corr(method = 'pearson')\n",
        "\n",
        "correlation_with_price_z = appartments_correlations['price_z_log'].sort_values(ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ckMis3hkH9P7"
      },
      "outputs": [],
      "source": [
        "appartments_selected_numeric_vars = correlation_with_price_z[correlation_with_price_z.abs() >= 0.03].index.tolist()\n",
        "\n",
        "if 'price_z' in appartments_selected_numeric_vars:\n",
        "    appartments_selected_numeric_vars.remove('price_z')\n",
        "if 'price_z_log' in appartments_selected_numeric_vars:\n",
        "    appartments_selected_numeric_vars.remove('price_z_log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyPiurxFID6V"
      },
      "source": [
        "## Qualitative (categorical) variables - correlations (nominal + ordinal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "2QxFpH7ZID6W"
      },
      "outputs": [],
      "source": [
        "appartments_categorical_variables = appartments_train.select_dtypes(include=[\"category\", \"object\"]).columns\n",
        "appartments_selected_categorical_vars = appartments_categorical_variables.to_list()\n",
        "appartments_selected_categorical_vars.remove('has_lift')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "qWrdX1j_UcBl"
      },
      "outputs": [],
      "source": [
        "encoded_cols = appartments_train_encoded.columns\n",
        "\n",
        "dummy_cols = []\n",
        "for cat_var in appartments_selected_categorical_vars:\n",
        "    matched = [col for col in encoded_cols if col.startswith(f\"{cat_var}_\")]\n",
        "    dummy_cols.extend(matched)\n",
        "appartments_selected_vars = appartments_selected_numeric_vars + dummy_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c79CKCzVEoY_"
      },
      "source": [
        "# Linear regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "bAWIyTtWEtJO"
      },
      "outputs": [],
      "source": [
        "y_train = appartments_train_encoded['price_z_log']\n",
        "X_train = sm.add_constant(appartments_train_encoded[appartments_selected_vars])\n",
        "X_test = sm.add_constant(appartments_test_encoded[appartments_selected_vars])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfs4u_e0EtG5",
        "outputId": "4487be49-f991-4a8a-b4f0-03ce8044f49d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:            price_z_log   R-squared:                       0.955\n",
            "Model:                            OLS   Adj. R-squared:                  0.955\n",
            "Method:                 Least Squares   F-statistic:                 9.546e+04\n",
            "Date:                Sat, 31 May 2025   Prob (F-statistic):               0.00\n",
            "Time:                        19:52:23   Log-Likelihood:             1.2875e+05\n",
            "No. Observations:              156454   AIC:                        -2.574e+05\n",
            "Df Residuals:                  156418   BIC:                        -2.571e+05\n",
            "Df Model:                          35                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================================\n",
            "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------------------\n",
            "const                         13.4428      0.001   1.11e+04      0.000      13.440      13.445\n",
            "market_volatility              0.4293      0.000    881.387      0.000       0.428       0.430\n",
            "dim_m2                         0.0302      0.001     57.969      0.000       0.029       0.031\n",
            "n_rooms                        0.0148      0.000     33.981      0.000       0.014       0.016\n",
            "estimated_maintenance_cost     0.0004      0.000      1.235      0.217      -0.000       0.001\n",
            "dist_centre                   -0.0080      0.001    -14.576      0.000      -0.009      -0.007\n",
            "n_poi                          0.0036      0.000      7.188      0.000       0.003       0.005\n",
            "dist_clinic                   -0.0035      0.000     -9.778      0.000      -0.004      -0.003\n",
            "dist_rest                     -0.0022      0.000     -5.457      0.000      -0.003      -0.001\n",
            "green_space_ratio              0.0024      0.000      5.472      0.000       0.002       0.003\n",
            "infrastructure_quality        -0.0097      0.000    -25.223      0.000      -0.010      -0.009\n",
            "obj_type_0d6c4dfc             -0.0068      0.001     -6.196      0.000      -0.009      -0.005\n",
            "obj_type_2a6d5c01              0.0145      0.001     11.849      0.000       0.012       0.017\n",
            "obj_type_None                 -0.0015      0.001     -1.258      0.208      -0.004       0.001\n",
            "own_type_4e625087              0.0218      0.035      0.616      0.538      -0.048       0.091\n",
            "own_type_bfb8fe10             -0.0057      0.001     -5.848      0.000      -0.008      -0.004\n",
            "build_mat_7f8c00f9            -0.0096      0.001     -9.149      0.000      -0.012      -0.008\n",
            "build_mat_None                -0.0014      0.001     -1.633      0.103      -0.003       0.000\n",
            "has_park_yes                   0.0050      0.001      7.739      0.000       0.004       0.006\n",
            "has_balcony_yes                0.0063      0.001     10.503      0.000       0.005       0.007\n",
            "has_sec_yes                    0.0065      0.001      7.309      0.000       0.005       0.008\n",
            "has_store_yes                 -0.0068      0.001    -10.854      0.000      -0.008      -0.006\n",
            "loc_code_143768f7             -0.0516      0.002    -29.323      0.000      -0.055      -0.048\n",
            "loc_code_378f340c              0.0310      0.001     27.519      0.000       0.029       0.033\n",
            "loc_code_3cb4aaff             -0.0451      0.002    -24.683      0.000      -0.049      -0.041\n",
            "loc_code_533f6886             -0.0875      0.002    -54.735      0.000      -0.091      -0.084\n",
            "loc_code_570cb745             -0.0629      0.003    -23.978      0.000      -0.068      -0.058\n",
            "loc_code_6900ba06              0.0122      0.002      7.325      0.000       0.009       0.015\n",
            "loc_code_693f303c              0.0537      0.001     48.921      0.000       0.052       0.056\n",
            "loc_code_765f79ed             -0.1062      0.002    -42.585      0.000      -0.111      -0.101\n",
            "loc_code_81b10147             -0.1087      0.003    -42.315      0.000      -0.114      -0.104\n",
            "loc_code_8d5a4f0c             -0.0719      0.001    -52.713      0.000      -0.075      -0.069\n",
            "loc_code_Other                -0.0453      0.003    -15.224      0.000      -0.051      -0.039\n",
            "loc_code_a6d54bd1             -0.0283      0.002    -17.473      0.000      -0.031      -0.025\n",
            "loc_code_e0cff11b              0.0207      0.001     16.771      0.000       0.018       0.023\n",
            "loc_code_ece39f3d             -0.0694      0.002    -36.397      0.000      -0.073      -0.066\n",
            "==============================================================================\n",
            "Omnibus:                    14190.755   Durbin-Watson:                   2.003\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4586.570\n",
            "Skew:                           0.111   Prob(JB):                         0.00\n",
            "Kurtosis:                       2.191   Cond. No.                         235.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        " appartments_model_full = sm.OLS(y_train, X_train).fit()\n",
        " print(appartments_model_full.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6JdWRut1ZWp"
      },
      "source": [
        "## Evaluating models using cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "YOk_NIx2MYe8"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# import numpy as np\n",
        "\n",
        "# def cross_val_ols(X, y, k=10):\n",
        "#     \"\"\"\n",
        "#     Perform k-fold cross-validation using OLS from statsmodels.\n",
        "#     Assumes X already includes a constant.\n",
        "\n",
        "#     Parameters:\n",
        "#         X (DataFrame): Feature matrix with constant included.\n",
        "#         y (Series): Target vector.\n",
        "#         k (int): Number of folds (default: 5)\n",
        "\n",
        "#     Returns:\n",
        "#         float: Mean RMSE across all folds\n",
        "#     \"\"\"\n",
        "#     kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "#     rmse_scores = []\n",
        "\n",
        "#     for train_idx, val_idx in kf.split(X):\n",
        "#         X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
        "#         y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "#         model = sm.OLS(y_train_cv, X_train_cv).fit()\n",
        "#         log_preds = model.predict(X_val_cv)\n",
        "\n",
        "#         # Back-transform both predictions and targets\n",
        "#         preds = np.exp(log_preds) - 1\n",
        "#         true_vals = np.exp(y_val_cv) - 1\n",
        "\n",
        "#         rmse = np.sqrt(mean_squared_error(true_vals, preds))\n",
        "#         rmse_scores.append(rmse)\n",
        "\n",
        "#     return np.mean(rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdnHZ4C_unuE",
        "outputId": "d2e755d8-a01c-439b-e029-90876420c546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV RMSE (Full): 95975.33495059048\n"
          ]
        }
      ],
      "source": [
        "# # Full model CV\n",
        "# rmse_cv_full = cross_val_ols(X_train, y_train)\n",
        "# print(\"CV RMSE (Full):\", rmse_cv_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_vaRY0Z7Oh-"
      },
      "source": [
        "#Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SsbOALP8h_pK",
        "outputId": "80bb46b8-c0e1-4b0c-f329-e5a96ca00518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to: /content/ols_predictions_final.csv\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1c2712b8-3504-4e08-ac05-ba9bb14b8cc2\", \"ols_predictions_final.csv\", 1376760)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred_log = appartments_model_full.predict(X_test)\n",
        "y_pred_real = np.expm1(y_pred_log)\n",
        "\n",
        "predictions_csv = pd.DataFrame({\n",
        "    'unit_id': unit_ids.values,\n",
        "    'prediction': y_pred_real\n",
        "})\n",
        "\n",
        "csv_path = \"/content/ols_predictions_final.csv\"\n",
        "predictions_csv.to_csv(csv_path, index=False)\n",
        "print(\"Predictions saved to:\", csv_path)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(csv_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
